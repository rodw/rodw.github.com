<!DOCTYPE html><html lang="en"><head><meta charset="utf-8"><title>15 one-liner snippets | HeyRod.com</title><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/bootstrap.min.css"><link rel="stylesheet" href="/css/font-awesome.min.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/hjs/railscasts.min.css"><style></style></head><body role="document"><nav class="navbar navbar-inverse" role="navigation"><div class="container"><div class="navbar-header"><button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#main-nav" aria-expanded="false"><span class="sr-only">Toggle navigation</span><span class="icon-bar"></span><span class="icon-bar"></span><span class="icon-bar"></span></button><a class="navbar-brand" href="/">HeyRod.com</a></div><div  id="main-nav" class="collapse navbar-collapse"><ul class="nav navbar-nav navbar-right"><li><a href="/"><i class='fa fa-home'></i>&nbsp;&nbsp;Home</a></li><li><a href="/projects/"><i class='fa fa-briefcase'></i>&nbsp;&nbsp;Projects</a></li><li><a href="/articles/"><i class='fa fa-book'></i>&nbsp;&nbsp;Articles</a></li><li class="active"><a href="/snippets/"><i class='fa fa-hashtag'></i>&nbsp;&nbsp;Snippets <span class="sr-only">(current)</span></a></li></ul></div></div></nav><div class="wrapper"><div class="main-container"><div class="container"><div class="row"><div class="col-md-2 text-center"><a href="/"><img src="/img/rod-fc-circle-on-white-200x200.png" height="100" width="100"></a><br>&nbsp;<br>Rodney Waldhoff<br><a href="http://heyrod.com/"><i class="fa fa-cloud"></i> HeyRod.com</a><br><a href="mailto:rwaldhoff+heyrod.com@gmail.com"><i class="fa fa-envelope"></i>  Email</a><br>&nbsp;<br><a href="https://github.com/rodw/"><i class="fa fa-github-alt"></i> GitHub</a><br><a href="http://stackoverflow.com/users/1225825/rod"><i class="fa fa-stack-overflow"></i> StackOverflow</a><br><a href="https://www.linkedin.com/in/rwald"><i class="fa fa-linkedin"></i> LinkedIn</a><br>&nbsp;</div><div class="col-md-10"><div class="row snippet-title"><div class="col-sm-7"><h1>15 one-liner snippets</h1></div><div class="col-sm-5 text-right snippet-title-right"><div class="text-right snippet-title-link"><a href="/snippets">Snippets</a> are tiny notes I've collected for easy reference.</div></div></div><div class="row"><div class="col-sm-12 snippet"><div class="permalink"><a href="/snippets/cli-for-html-extraction.html" title="permalink for this snippet"><i class="fa fa-link"></i></a></div><h1 id="command-line-tool-for-spidering-sites-and-extracting-xml-html-content">Command-line tool for spidering sites and extracting XML/HTML content</h1>
<p><a href="http://videlibri.sourceforge.net/xidel.html"><strong>Xidel</strong></a> is a robust tool for spidering, extracting and transforming XML/HTML content from the command line.</p>
<p>It&#39;s like <code>wget</code> or <code>curl</code> with a CSS and XPath/XQuery engine (among other features), attached.</p>
<p><code>xidel</code> doesn&#39;t seem to be in the package management repositories I normally use, but you can <a href="http://videlibri.sourceforge.net/xidel.html#downloads">download it here</a>.</p>
<p>The following example will (1) download a web page, (2) extract a list of links (specified via CSS selector) from it, (3) download the page corresponding to each of those links and finally (4) extract specific pieces of content (specified by CSS selectors) from each page:</p>
<pre><code class="lang-bash">xidel [URL-OF-INDEX-PAGE] \
  --follow &quot;css(&#39;[CSS-SELECTOR-FOR-LINKS]&#39;)&quot; \
  --css &quot;[CSS-SELECTOR-FOR-SOME-TEXT]&quot; \
  --extract &quot;inner-html(css(&#39;[CSS-SELECTOR-FOR-SOME-HTML]&#39;))&quot;
</code></pre>
<p>As a concrete example, the command:</p>
<pre><code class="lang-bash">$ xidel http://reddit.com -f  &quot;css(&#39;a&#39;)&quot; --css title
</code></pre>
<p>will download every page linked from the reddit.com homepage and print the content of its <code>title</code> tag.</p>
<p>There are several more <a href="http://videlibri.sourceforge.net/xidel.html#examples">examples on the Xidel site</a>.</p>
<div class="pubdate">Published 11 Feb 2014</div><div class="tags">Tagged <a href="tag-linux.html">linux</a>, <a href="tag-tool.html">tool</a>, <a href="tag-xml.html">xml</a>, <a href="tag-css.html">css</a>, <a href="tag-html.html">html</a>, <a href="tag-xpath.html">xpath</a>, <a href="tag-one-liner.html">one-liner</a> and <a href="tag-ops.html">ops</a>.</div></div></div><br>&nbsp;</br><div class="row"><div class="col-sm-12 snippet"><div class="permalink"><a href="/snippets/download-website-with-wget.html" title="permalink for this snippet"><i class="fa fa-link"></i></a></div><h1 id="backup-or-mirror-a-website-using-wget">Backup or mirror a website using wget</h1>
<p>To create a local mirror or backup of a website with <code>wget</code>, run:</p>
<pre><code class="lang-bash">wget -r -l 5 -k -w 1 --random-wait &lt;URL&gt;
</code></pre>
<p>Where:</p>
<ul>
<li><code>-r</code> (or <code>--recursive</code>) will cause <code>wget</code> to recursively download files</li>
<li><code>-l N</code> (or <code>--level=N</code>) will limit recursion to at most N levels below the root document (defaults to 5, use <code>inf</code> for infinite recursion)</li>
<li><code>-k</code> (or <code>--convert-links</code>) will cause <code>wget</code> to convert links in the downloaded documents so that the files can be viewed locally</li>
<li><code>-w</code> (or <code>--wait=N</code>) will cause <code>wget</code> to wait N seconds between requests</li>
<li><code>--random-wait</code> will cause <code>wget</code> to randomly vary the wait time to <code>0.5x</code> to <code>1.5x</code> the value specified by <code>--wait</code></li>
</ul>
<p>Some additional notes:</p>
<ul>
<li><code>--mirror</code> (or <code>-m</code>) can be used as a shortcut for <code>-r -N -l inf --no-remove-listing</code> which enables infinite recursion and preserves both the server timestamps and FTP directory listings.</li>
<li><code>-np</code> (<code>--no-parent</code>) can be used to limit <code>wget</code> to files below a specific &quot;directory&quot; (path).</li>
</ul>
<div class="pubdate">Published 10 Feb 2014</div><div class="tags">Tagged <a href="tag-wget.html">wget</a>, <a href="tag-linux.html">linux</a>, <a href="tag-http.html">http</a>, <a href="tag-one-liner.html">one-liner</a>, <a href="tag-web.html">web</a>, <a href="tag-backup.html">backup</a>, <a href="tag-tool.html">tool</a> and <a href="tag-ops.html">ops</a>.</div></div></div><br>&nbsp;</br><div class="row"><div class="col-sm-12 snippet"><div class="permalink"><a href="/snippets/pre-cache-with-wget.html" title="permalink for this snippet"><i class="fa fa-link"></i></a></div><h1 id="pre-generate-pages-or-load-a-web-cache-using-wget">Pre-generate pages or load a web cache using wget</h1>
<p>Many web frameworks and template engines will defer the generation the HTML version of a document the first time it is accessed.  This can make the first hit on a given page significantly slower than subsequent hits.</p>
<p>You can use <code>wget</code> to pre-cache web pages using a command such as:</p>
<pre><code class="lang-bash">wget -r -l 3 -nd --delete-after &lt;URL&gt;
</code></pre>
<p>Where:</p>
<ul>
<li><code>-r</code> (or <code>--recursive</code>) will cause <code>wget</code> to recursively download files</li>
<li><code>-l N</code> (or <code>--level=N</code>) will limit recursion to at most N levels below the root document (defaults to 5, use <code>inf</code> for infinite recursion)</li>
<li><code>-nd</code> (or <code>--no-directories</code>) will prevent <code>wget</code> from creating local directories to match the server-side paths</li>
<li><code>--delete-after</code> will cause <code>wget</code> to delete each file as soon as it is downloaded (so the command leaves no traces behind.)</li>
</ul>
<div class="pubdate">Published 10 Feb 2014</div><div class="tags">Tagged <a href="tag-wget.html">wget</a>, <a href="tag-linux.html">linux</a>, <a href="tag-http.html">http</a>, <a href="tag-one-liner.html">one-liner</a>, <a href="tag-performance.html">performance</a>, <a href="tag-web.html">web</a>, <a href="tag-tool.html">tool</a> and <a href="tag-ops.html">ops</a>.</div></div></div><br>&nbsp;</br><div class="row"><div class="col-sm-12 snippet"><div class="permalink"><a href="/snippets/iptables-port-mapping.html" title="permalink for this snippet"><i class="fa fa-link"></i></a></div><h1 id="mapping-port-80-to-port-3000-using-iptables">Mapping port 80 to port 3000 using iptables</h1>
<p>Port numbers less that 1024 are considered &quot;privileged&quot; ports, and you generally must be <code>root</code> to bind a listener to them.</p>
<p>Rather than running a network application as <code>root</code>, map the privileged port to a non-privileged one:</p>
<pre><code class="lang-bash">sudo iptables -A PREROUTING -t nat -i eth0 -p tcp --dport 80 -j REDIRECT --to-port 3000
</code></pre>
<p>Now requests to port 80 will be forwarded on to port 3000.</p>
<div class="pubdate">Published 8 Feb 2014</div><div class="tags">Tagged <a href="tag-linux.html">linux</a>, <a href="tag-networking.html">networking</a>, <a href="tag-iptables.html">iptables</a>, <a href="tag-one-liner.html">one-liner</a>, <a href="tag-http.html">http</a>, <a href="tag-tool.html">tool</a> and <a href="tag-ops.html">ops</a>.</div></div></div><br>&nbsp;</br><div class="row"><div class="col-sm-12 snippet"><div class="permalink"><a href="/snippets/graphviz-txlib.html" title="permalink for this snippet"><i class="fa fa-link"></i></a></div><h1 id="quickly-render-a-dot-graphviz-graph">Quickly render a &#39;dot&#39; (Graphviz) graph</h1>
<p>On Linux and OSX the command:</p>
<pre><code class="lang-bash">dot -Txlib mygraph.gv
</code></pre>
<p>will quickly launch a lightweight window containing a <code>dot</code> rendering of the graph in <code>mygraph.gv</code>.</p>
<p>The rendering should automatically refresh when <code>mygraph.gv</code> is updated.  (I&#39;ve occasionally run into small glitches with this that force me to re-launch the window, but they are rare and obvious.)</p>
<p>The same <code>-Txlib</code> parameter works for the other Graphviz rendering engines, including <code>neato</code>, <code>twopi</code>, <code>fdp</code>, <code>sfdp</code>, <code>circo</code>, and <code>patchwork</code>.</p>
<div class="pubdate">Published 1 Jan 2014</div><div class="tags">Tagged <a href="tag-graphviz.html">graphviz</a>, <a href="tag-linux.html">linux</a>, <a href="tag-one-liner.html">one-liner</a> and <a href="tag-tool.html">tool</a>.</div></div></div><br>&nbsp;</br><div class="row"><div class="col-sm-12 snippet"><div class="permalink"><a href="/snippets/less-chop-long-lines.html" title="permalink for this snippet"><i class="fa fa-link"></i></a></div><h1 id="use-less-s-for-horizontal-scrolling">Use &#39;less -S&#39; for horizontal scrolling</h1>
<p>The flag <code>-S</code> (or <code>--chop-long-lines</code>) will cause <code>less</code> to truncate lines at the screen (terminal) boundary, rather than wrapping as it does by default.  You can then scroll horizontally (with the arrow keys, for example) to view the full lines when needed.</p>
<pre><code class="lang-bash">cat some_file_with_very_long_lines | less -S
</code></pre>
<div class="tags">Tagged <a href="tag-bash.html">bash</a>, <a href="tag-linux.html">linux</a>, <a href="tag-one-liner.html">one-liner</a> and <a href="tag-cli.html">cli</a>.</div></div></div><br>&nbsp;</br><div class="row"><div class="col-sm-12 snippet"><div class="permalink"><a href="/snippets/find-duplicates-on-linux.html" title="permalink for this snippet"><i class="fa fa-link"></i></a></div><h1 id="find-duplicate-files-on-linux-or-osx-">Find duplicate files on Linux (or OSX).</h1>
<p>Find files that have the same size and MD5 hash (and hence are likely to be exact duplicates):</p>
<pre><code class="lang-bash">find -not -empty -type f -printf &quot;%s\n&quot; | \         # line 1
  sort -rn | \                                      # line 2
  uniq -d | \                                       # line 3   
  xargs -I{} -n1 find -type f -size {}c -print0 | \ # line 4
  xargs -0 md5sum | \                               # line 5
  sort | \                                          # line 6
  uniq -w32 --all-repeated=separate | \             # line 7
  cut -d&quot; &quot; -f3-                                    # line 8
</code></pre>
<p>You probably want to pipe that to a file as it runs slowly.</p>
<ol>
<li>Line 1 enumerates the real files non-empty by size.</li>
<li>Line 2 sorts the sizes (as numbers of descending size).</li>
<li>Line 3 strips out the lines (sizes) that only appear once.</li>
<li>For each remaining size, line 4 finds all the files of that size.</li>
<li>Line 5 computes the MD5 hash for all the files found in line 4, outputting the MD5 hash and file name. (This is repeated for each set of files of a given size.)</li>
<li>Line 6 sorts that list for easy comparison.</li>
<li>Line 7 compares the first 32 characters of each line (the MD5 hash) to find duplicates.</li>
<li>Line 8 spits out the file name and path part of the matching lines.</li>
</ol>
<p>Some alternative approaches can be found at <a href="http://www.commandlinefu.com/commands/view/3555/find-duplicate-files-based-on-size-first-then-md5-hash">the original source</a>.</p>
<div class="tags">Tagged <a href="tag-linux.html">linux</a>, <a href="tag-one-liner.html">one-liner</a> and <a href="tag-ops.html">ops</a>.</div></div></div><br>&nbsp;</br><div class="row"><div class="col-sm-12 snippet"><div class="permalink"><a href="/snippets/shuf-usr-share-dict-words.html" title="permalink for this snippet"><i class="fa fa-link"></i></a></div><h1 id="generate-a-random-list-of-words-with-shuf-">Generate a random list of words with <code>shuf</code></h1>
<p><code>shuf</code> is (in my experience) a little known GNU utility that selects random lines (or bytes) from a file.</p>
<p>For instance, the command:</p>
<pre><code class="lang-bash">shuf -n 3 /usr/share/dict/words
</code></pre>
<p>selects three words at random from the <code>words</code> dictionary.</p>
<div class="tags">Tagged <a href="tag-linux.html">linux</a>, <a href="tag-one-liner.html">one-liner</a> and <a href="tag-tool.html">tool</a>.</div></div></div><br>&nbsp;</br><div class="row"><div class="col-sm-12 snippet"><div class="permalink"><a href="/snippets/find-large-files.html" title="permalink for this snippet"><i class="fa fa-link"></i></a></div><h1 id="find-large-files-on-linux-">Find large files on Linux.</h1>
<p><strong>UPDATE:</strong> Reader Luc Pionchon points out that <code>sort</code> often supports a <code>-h</code> parameter that sorts by &quot;human&quot; numbers, hence:</p>
<pre><code class="lang-bash">$ du -h * | sort -h | tail
</code></pre>
<p>is probably a better alternative than any of the following (for the systems that support it).</p>
<pre><code class="lang-bash">du -h * | grep &quot;^[0-9.]*M&quot; | sort -n
</code></pre>
<p>This finds files at least 1 MB in size and then sorts them by size.  Change <code>M</code> to <code>G</code> for files at least 1 GB in size.</p>
<p>(Caveat: files 1 GB or larger will be missed by the MB version.  You can use:</p>
<pre><code class="lang-bash">du -h * | egrep &quot;^[0-9.]*(M|G)&quot;
</code></pre>
<p>to get both, but then the <code>sort -n</code> doesn&#39;t work quite the way we&#39;d like.)</p>
<p>Of course, you could use <code>du</code> without the <code>-h</code> to get file sizes by the default block size rather than the human-readable 12.4M or 16K, etc.</p>
<div class="tags">Tagged <a href="tag-linux.html">linux</a>, <a href="tag-one-liner.html">one-liner</a> and <a href="tag-tool.html">tool</a>.</div></div></div><br>&nbsp;</br><div class="row"><div class="col-sm-12 snippet"><div class="permalink"><a href="/snippets/strip-chars-with-awk.html" title="permalink for this snippet"><i class="fa fa-link"></i></a></div><h1 id="strip-characters-from-a-field-in-awk-">Strip characters from a field in &#39;awk&#39;</h1>
<p>E.g., the following command strips alpha characters from the second (tab delimited) field.</p>
<pre><code class="lang-bash">awk -F&quot;\t&quot; &#39;{gsub(/[A-Za-z]/,&quot;&quot;,$2); print $2 }&#39;
</code></pre>
<div class="tags">Tagged <a href="tag-linux.html">linux</a>, <a href="tag-awk.html">awk</a>, <a href="tag-tool.html">tool</a> and <a href="tag-one-liner.html">one-liner</a>.</div></div></div><br>&nbsp;</br><div class="row"><div class="col-sm-12 snippet"><div class="permalink"><a href="/snippets/strip-chars-with-sed.html" title="permalink for this snippet"><i class="fa fa-link"></i></a></div><h1 id="strip-characters-from-a-string-or-file-with-sed-">Strip characters from a string or file with &#39;sed&#39;</h1>
<pre><code class="lang-bash">$ echo &quot;A1B2C3&quot; | sed &#39;s/[A-Z]//g&#39;
123
</code></pre>
<div class="tags">Tagged <a href="tag-linux.html">linux</a>, <a href="tag-sed.html">sed</a>, <a href="tag-tool.html">tool</a> and <a href="tag-one-liner.html">one-liner</a>.</div></div></div><br>&nbsp;</br><div class="row"><div class="col-sm-12 snippet"><div class="permalink"><a href="/snippets/python-pretty-print-json-tool.html" title="permalink for this snippet"><i class="fa fa-link"></i></a></div><h1 id="pretty-print-json-with-python-s-json-tool">Pretty-print JSON with Python&#39;s json.tool</h1>
<p>Pretty-print a JSON file using Python (v2.5+)&#39;s built-in <code>json.tool</code> module:</p>
<pre><code class="lang-bash">cat MYFILE.json | python -m json.tool
</code></pre>
<div class="pubdate">Published 15 Feb 2014</div><div class="tags">Tagged <a href="tag-python.html">python</a>, <a href="tag-json.html">json</a>, <a href="tag-cli.html">cli</a> and <a href="tag-one-liner.html">one-liner</a>.</div></div></div><br>&nbsp;</br><div class="row"><div class="col-sm-12 snippet"><div class="permalink"><a href="/snippets/python-csv-to-json-array.html" title="permalink for this snippet"><i class="fa fa-link"></i></a></div><h1 id="python-one-liner-for-reading-a-csv-file-into-a-json-array-of-arrays">Python one-liner for reading a CSV file into a JSON array of arrays</h1>
<p>Reading a CSV file into 2-d Python array (an array of arrays):</p>
<pre><code class="lang-python">import csv
array = list(csv.reader(open( MYFILE.csv )))
</code></pre>
<p>Dumping that as JSON (via the command-line):</p>
<pre><code class="lang-bash">$ python -c &quot;import json,csv;print json.dumps(list(csv.reader(open( CSV-FILENAME ))))&quot;
</code></pre>
<div class="pubdate">Published 15 Feb 2014</div><div class="tags">Tagged <a href="tag-python.html">python</a>, <a href="tag-json.html">json</a>, <a href="tag-cli.html">cli</a> and <a href="tag-one-liner.html">one-liner</a>.</div></div></div><br>&nbsp;</br><div class="row"><div class="col-sm-12 snippet"><div class="permalink"><a href="/snippets/python-static-web-server.html" title="permalink for this snippet"><i class="fa fa-link"></i></a></div><h1 id="launch-an-http-server-serving-the-current-directory-using-python">Launch an HTTP server serving the current directory using Python</h1>
<p>The Python <code>SimpleHTTPServer</code> module makes it easy to launch a simple web server using a current working directory as the &quot;docroot&quot;.</p>
<p>With Python 2:</p>
<pre><code class="lang-bash">python -m SimpleHTTPServer
</code></pre>
<p>or with Python 3:</p>
<pre><code class="lang-bash">python3 -m http.server
</code></pre>
<p>By default, each will bind to port 8080, hence <code>http://localhost:8080/</code> will serve the top level of the working directory tree.  Hit <code>Ctrl-c</code> to stop.</p>
<p>Both accept an optional port number:</p>
<pre><code class="lang-bash">python -m SimpleHTTPServer 3001
</code></pre>
<p>or</p>
<pre><code class="lang-bash">python3 -m http.server 3001
</code></pre>
<p>if you want to bind to something other than port 8080.</p>
<div class="pubdate">Published 20 Feb 2014</div><div class="tags">Tagged <a href="tag-python.html">python</a>, <a href="tag-http.html">http</a>, <a href="tag-cli.html">cli</a>, <a href="tag-one-liner.html">one-liner</a>, <a href="tag-ops.html">ops</a> and <a href="tag-tool.html">tool</a>.</div></div></div><br>&nbsp;</br><div class="row"><div class="col-sm-12 snippet"><div class="permalink"><a href="/snippets/git-bundle.html" title="permalink for this snippet"><i class="fa fa-link"></i></a></div><h1 id="backup-a-git-repository-with-git-bundle-">backup a git repository with &#39;git bundle&#39;</h1>
<p>Run:</p>
<pre><code class="lang-bash">cd REPOSITORY_WORKING_DIRECTORY
git bundle create PATH_TO_BUNDLE.git --all
</code></pre>
<p>to create a single-file backup of the entire repository.</p>
<p>Note that the bundle file is a functional Git repository:</p>
<pre><code>git clone PATH_TO_BUNDLE.git MY_PROJECT
</code></pre><div class="tags">Tagged <a href="tag-git.html">git</a>, <a href="tag-backup.html">backup</a>, <a href="tag-one-liner.html">one-liner</a>, <a href="tag-ops.html">ops</a> and <a href="tag-tool.html">tool</a>.</div></div></div><br>&nbsp;</br><div class="row"><div class="col-sm-12 text-right snippet-title-right"><div class="text-right snippet-title-link"><a href="/snippets">Snippets</a> are tiny notes I've collected for easy reference.</div></div></div></div></div></div></div></div><hr style="width:100%"><div class="container"><div class="row"><div class="col-md-4 text-muted">This page was generated at 9:57 PM on 10 Dec 2015.</div><div class="col-md-4 text-muted text-center"><a href="http://heyrod.com/">HeyRod.com</a></div><div class="col-md-4 text-muted text-right">Copyright &copy; 1999 - 2015 Rodney Waldhoff.</div><br>&nbsp;</div></div><script src="/js/bootstrap.min.js"></script><script src="/js/ugly.js"></script><script src="/js/highlight.min.js"></script><script type="text/javascript">var _gaq = _gaq || [];_gaq.push(['_setAccount', 'UA-34329491-1']);_gaq.push(['_trackPageview']);(function() {var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);})();</script></body></html>